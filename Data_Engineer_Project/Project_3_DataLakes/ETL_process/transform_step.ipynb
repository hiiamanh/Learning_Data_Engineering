{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e8b612f-bdb7-4f1b-af11-0b158e4b523d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Transform the data into the star schema for a Gold data store;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55f74588-9903-43f0-b68f-bb81020b1e3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import TimestampType\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21973c68-69f5-4187-a24e-eb3ce144ed89",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Table fact_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29d56082-a7d1-4f3b-8e59-9065045f58f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+--------+\n|payment_id|      date|amount|rider_id|\n+----------+----------+------+--------+\n|       154|2018-03-01|  8.63|    1007|\n|       493|2021-08-01|   9.0|    1020|\n|       760|2019-03-01|   9.0|    1032|\n|       819|2021-08-01|  20.9|    1034|\n|       962|2015-06-01|   9.0|    1040|\n+----------+----------+------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Create dataframe\n",
    "payments_df = spark.table(\"staging_payments\")\n",
    "payments_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f2324f1-7586-4fad-acdb-034bb69493c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create table\n",
    "spark.sql(\"DROP TABLE IF EXISTS fact_payments\")\n",
    "payments_df.write.format(\"delta\")   \\\n",
    "                 .mode(\"overwrite\") \\\n",
    "                 .saveAsTable(\"fact_payment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b12e57c-6787-43d6-8581-a3c04426af42",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Table dim_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00b16011-1092-4951-8e8a-13c9318c0c64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------------+------------------+\n|  station_id|                name|         latitude|         longitude|\n+------------+--------------------+-----------------+------------------+\n|       13277|Broadway & Belmon...|        41.940106|        -87.645451|\n|      RP-002|    Warren Park East|   42.00454962194|    -87.6806661451|\n|       16916|Central Ave & Mad...|41.88016233333333|-87.76319483333332|\n|         319|     Roscoe & Harlem|            41.94|            -87.81|\n|TA1305000002|Wabash Ave & Roos...|        41.867227|        -87.625961|\n+------------+--------------------+-----------------+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Create dataframe\n",
    "stations_df = spark.table(\"staging_stations\")\n",
    "stations_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a8b7fc3-88ad-4306-86dd-9c07a8556d0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create table\n",
    "spark.sql(\"DROP TABLE IF EXISTS dim_stations\")\n",
    "stations_df.write.format(\"delta\")   \\\n",
    "                 .mode(\"overwrite\") \\\n",
    "                 .saveAsTable(\"dim_stations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75b28766-79a4-42bf-855f-b15e55236b25",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Table dim_riders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0b99a10-1e9e-45bb-8afa-31a7d93ef26c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----------+--------------------+----------+------------------+----------------+---------+\n|rider_id|  address|first_name|           last_name|  birthday|account_start_date|account_end_date|is_member|\n+--------+---------+----------+--------------------+----------+------------------+----------------+---------+\n|    1076|    David|     Lewis| 189 Deborah Estates|1991-11-13|        2019-12-26|            null|     True|\n|    1081|  Raymond|      Wang|35233 Griffin Ran...|1993-01-26|        2019-10-31|            null|     True|\n|    1353|Elizabeth|      Byrd|666 Villanueva Po...|1972-12-26|        2021-11-25|            null|     True|\n|    1721|    Maria|       Cox|85213 Thomas Expr...|1999-07-04|        2014-08-01|            null|     True|\n|    1933|   Robert|   Francis|52423 Roberts Byp...|1986-07-27|        2021-06-23|            null|     True|\n+--------+---------+----------+--------------------+----------+------------------+----------------+---------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Create dataframe\n",
    "rider_df = spark.table(\"staging_riders\")\n",
    "rider_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cbcc09a-8134-4ab0-9509-5eb26238ffaf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create table\n",
    "spark.sql(\"DROP TABLE IF EXISTS dim_riders\")\n",
    "rider_df.write.format(\"delta\")   \\\n",
    "                 .mode(\"overwrite\") \\\n",
    "                 .saveAsTable(\"dim_riders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c291b6b3-9f67-4cdf-ae06-45a7fec2b2cd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Table fact_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de36455f-184a-4dcb-a79a-701085bc4509",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+-------------+-------------------+-------------------+--------+---------+----------------+--------------+\n|         trip_id|rider_id|rideable_type|         started_at|           ended_at|duration|rider_age|start_station_id|end_station_id|\n+----------------+--------+-------------+-------------------+-------------------+--------+---------+----------------+--------------+\n|AFA0D5E6BCCB4364|   13758| classic_bike|2021-02-27 09:42:27|2021-02-27 10:05:18|    23.0|     24.0|           13058|         13156|\n|B1893BA60B66971B|   28569| classic_bike|2021-02-14 23:28:58|2021-02-14 23:45:19|    16.0|     24.0|    TA1307000107|  TA1309000025|\n|08244C4BC7103B93|   32453| classic_bike|2021-02-06 12:09:41|2021-02-06 12:47:28|    38.0|     52.0|             517|           523|\n|E53F1483EE997E22|   73224| classic_bike|2021-02-20 14:07:16|2021-02-20 14:20:34|    13.0|     39.0|           15622|  TA1309000026|\n|13FEB69519CCA839|   30873|electric_bike|2021-02-01 15:47:23|2021-02-01 16:01:14|    14.0|     22.0|    TA1309000004|         13194|\n+----------------+--------+-------------+-------------------+-------------------+--------+---------+----------------+--------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "trips = spark.table(\"staging_trips\")\n",
    "fact_trips = trips.join(rider_df, trips.rider_id == rider_df.rider_id, \"left\" ) \\\n",
    "            .withColumn('duration', round((unix_timestamp(\"ended_at\") - unix_timestamp('started_at'))/60)) \\\n",
    "            .withColumn('rider_age', round(datediff(to_date(rider_df.account_start_date), to_date(rider_df.birthday))/365.25)) \\\n",
    "            .select(\"trip_id\",\"staging_trips.rider_id\",\"rideable_type\",\"started_at\",\"ended_at\",\"duration\",\"rider_age\",\"start_station_id\",\"end_station_id\")\n",
    "fact_trips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f90b172e-4792-4b61-8d19-b77471c69680",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create table\n",
    "spark.sql(\"DROP TABLE IF EXISTS fact_trips\")\n",
    "fact_trips.write.format(\"delta\")   \\\n",
    "                 .mode(\"overwrite\") \\\n",
    "                 .saveAsTable(\"fact_trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b507939-c9b1-404b-967c-d8de77e4f032",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Create dimDate table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8e64e0c-fbb0-4239-96a0-b8bedc1d2c12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+-----+-------+----+\n|            date_id|day_of_week|day_of_month|month|quarter|year|\n+-------------------+-----------+------------+-----+-------+----+\n|2021-02-01 00:00:00|          2|           1|    2|      1|2021|\n|2021-02-02 00:00:00|          3|           2|    2|      1|2021|\n|2021-02-03 00:00:00|          4|           3|    2|      1|2021|\n|2021-02-04 00:00:00|          5|           4|    2|      1|2021|\n|2021-02-05 00:00:00|          6|           5|    2|      1|2021|\n+-------------------+-----------+------------+-----+-------+----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Get min date from trips\n",
    "min_date = trips.selectExpr('MIN(started_at) AS started_at').first().asDict()['started_at']\n",
    "# Get max date from trips\n",
    "max_date = trips.selectExpr('MAX(started_at) AS started_at').first().asDict()['started_at']\n",
    "expression = f\"sequence(to_date('{min_date}'), to_date('{max_date}'), interval 1 day)\"\n",
    "dim_date = spark.createDataFrame([(1,)], [\"date_id\"])\n",
    "\n",
    "dim_date = dim_date.withColumn(\"dateinit\", f.explode(f.expr(expression)))\n",
    "dim_date = dim_date.withColumn(\"date\", f.to_timestamp(dim_date.dateinit, \"yyyy-MM-dd\"))\n",
    "\n",
    "dim_date = dim_date \\\n",
    "            .withColumn(\"day_of_week\", f.dayofweek(dim_date.date)) \\\n",
    "            .withColumn(\"day_of_month\", f.dayofmonth(dim_date.date)) \\\n",
    "            .withColumn(\"month\", f.month(dim_date.date)) \\\n",
    "            .withColumn(\"quarter\", f.quarter(dim_date.date)) \\\n",
    "            .withColumn(\"year\", f.year(dim_date.date)) \\\n",
    "            .withColumn(\"date_id\", dim_date.date.cast(StringType())) \\\n",
    "            .drop(f.col(\"dateinit\")) \\\n",
    "            .drop(f.col(\"date\")) \n",
    "dim_date.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb2a8e4b-822c-4856-9f3a-eb76c61318ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create table\n",
    "spark.sql(\"DROP TABLE IF EXISTS dim_date\")\n",
    "fact_trips.write.format(\"delta\")   \\\n",
    "                 .mode(\"overwrite\") \\\n",
    "                 .saveAsTable(\"dim_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "690833a4-9c49-4ee8-b0ae-9158f18d3937",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "transform_step",
   "notebookOrigID": 3715339129031194,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
